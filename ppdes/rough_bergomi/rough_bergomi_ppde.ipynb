{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iJv2D01QRPTO",
    "outputId": "9ed45d1c-0f86-4326-affe-728ce8bd47f7"
   },
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/crispitagorico/sigkernel.git\n",
    "# !git clone 'https://github.com/ryanmccrickerd/rough_bergomi.git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rCD6FgadFjvr"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from rbergomi import rBergomi, rBergomi_MC_pricer, rBergomi_sigkernel_pricer\n",
    "from utils import r2, generate_evaluation_paths\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\", color_codes=True)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "T5q7TYWVPtbN"
   },
   "outputs": [],
   "source": [
    "n_samples_MC = 30000\n",
    "n_increments = 20\n",
    "\n",
    "m   = 300   # collocation points interior\n",
    "n   = 300    # collocation points boundary\n",
    "T   = 1.\n",
    "a   = -0.4  \n",
    "xi  = 0.055 \n",
    "eta = 1.9\n",
    "rho = -0.9\n",
    "\n",
    "x_mean = 2.\n",
    "x_var  = 1.\n",
    "\n",
    "sigma_t      = 1.\n",
    "sigma_x      = 1.\n",
    "sigma_sig    = 100.\n",
    "max_batch    = 10 \n",
    "dyadic_order = 3\n",
    "\n",
    "log_strike      = 2.  \n",
    "payoff_eur_call = lambda x: max(np.exp(x) - np.exp(log_strike), 0.) \n",
    "\n",
    "n_eval       = 20\n",
    "t_inds_eval  = np.random.choice(n_increments, n_eval)\n",
    "xs_eval      = np.array(np.random.normal(loc=log_strike, scale=0.5, size=n_eval))\n",
    "paths_eval   = generate_evaluation_paths(t_inds_eval, n_increments, T, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_mc_pricer        = rBergomi_MC_pricer(n_increments, n_samples_MC, T, a, xi, eta, rho)\n",
    "rb_sigkernel_pricer = rBergomi_sigkernel_pricer(n_increments, x_mean, x_var, m, n, T, a, xi, eta, rho, \n",
    "                                                sigma_t, sigma_x, sigma_sig, dyadic_order, max_batch, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.65 s, sys: 5.31 ms, total: 4.65 s\n",
      "Wall time: 4.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mc_prices = rb_mc_pricer.fit_predict(t_inds_eval, xs_eval, paths_eval, payoff_eur_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_sigkernel_pricer.fit(payoff_eur_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sigkernel_prices = rb_sigkernel_pricer.predict(t_inds_eval, xs_eval, paths_eval) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mc_prices, label='mc_prices')\n",
    "plt.plot(sigkernel_prices, label='sigkernel_Prices')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "fig = sns.jointplot(x=mc_prices, y=sigkernel_prices, kind='reg')\n",
    "fig.set_axis_labels('mc_prices', 'sigkernel_prices') \n",
    "plt.title(f\"Collocation points: {m+n} --- $R^2$ = {np.round(r2(mc_prices, sigkernel_prices), 2)}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # gradient descent parameters\n",
    "# phi          = lambda x: max(x - np.exp(log_strike), 0.)  \n",
    "# lr           = 1e-2\n",
    "# n_iter       = 100\n",
    "# print_every  = 5\n",
    "# batch_size   = 100\n",
    "# lambda_      = 0.5\n",
    "# penalty      = 1e-5\n",
    "# dt_scheduler = 50\n",
    "# x_scheduler  = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "AZZC035Y-e6z"
   },
   "outputs": [],
   "source": [
    "# t_ind_try, t_try, x_try, T_try, K_try = generator(m, n_increments+1, T, mid_price, a, xi, eta, rho)\n",
    "# fig, ax = plt.subplots(1, 2, figsize=(10,4))\n",
    "# for j in range(N):\n",
    "#     ax[0].plot(T_try[j,:,0], T_try[j,:,1], color='blue', alpha=0.1)\n",
    "#     ax[1].plot(K_try[j,:,1], color='red', alpha=0.1)\n",
    "# ax[0].set_title('Evaluation paths')\n",
    "# ax[1].set_title('Directions')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_paths = generate_evaluation_paths(t_ind_try, n_increments, T, a)\n",
    "# rb_sigkernel = rBergomi_sigkernel_pricer(n_increments, mid_price, m, n, T, a, xi, eta, rho, \n",
    "#                                          sigma_t, sigma_x, sigma_sig, max_batch, device)\n",
    "# rb_sigkernel.fit(payoff_eur_call)\n",
    "# directions = rb_sigkernel.directions\n",
    "# fig, ax = plt.subplots(1, 2, figsize=(10,4))\n",
    "# for j in range(m):\n",
    "#     ax[0].plot(eval_paths[j,:,0], eval_paths[j,:,1], color='blue', alpha=0.1)\n",
    "#     ax[1].plot(directions[j,:,1], color='red', alpha=0.1)\n",
    "# ax[0].set_title('Evaluation paths')\n",
    "# ax[1].set_title('Directions')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_fFz3dCxF46P"
   },
   "outputs": [],
   "source": [
    "# def exp_kernel(x, y, sigma):\n",
    "#     return torch.exp(-(x-y)**2/(2.*sigma**2))\n",
    "\n",
    "# def K(s, t, a):\n",
    "#     return (s-t)**a\n",
    "\n",
    "# def psi(t, x, a, xi, eta):\n",
    "#     return xi*torch.exp(eta*np.sqrt(2*a+1)*x-(eta**2/2)*t**(2*a-1))\n",
    "\n",
    "# def r2(x, y):\n",
    "#     return scipy.stats.pearsonr(x, y)[0] ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "oTOBayT5F8UQ"
   },
   "outputs": [],
   "source": [
    "# def generator(n_samples, n_steps, T, x0, a, xi, eta, rho, random_state=None):\n",
    "\n",
    "#     \"\"\"Returns: \n",
    "#                 - idx: tensor of shape (n_samples,) of randomly chosen indices in {0,1,...,n_steps-1}\n",
    "#                 - ts: tensor of shape (n_samples,) of time indices in [0,T]\n",
    "#                 - xs: tensor of shape (n_samples,) of prices ~ N(x0, 1)\n",
    "#                 - Ts: tensor of shape (n_samples, n_steps, 2) of time-augmented paths Theta^t with t in ts\n",
    "#                 - Ks: tensor of shape (n_samples, n_steps, 2) of time-augmented paths K^t with t in ts\n",
    "#     \"\"\"\n",
    "\n",
    "#     # set random state\n",
    "#     np.random.seed(random_state)\n",
    "\n",
    "#     # time steps\n",
    "#     dt = T/n_steps\n",
    "\n",
    "#     # time grid\n",
    "#     t_grid = torch.linspace(0., T, n_steps)\n",
    "    \n",
    "#     # random time indices\n",
    "#     idx = np.random.choice(np.arange(n_steps), n_samples)\n",
    "\n",
    "#     # initialize arrays\n",
    "#     ts = torch.zeros((n_samples,), dtype=torch.float64)\n",
    "#     xs = torch.normal(mean=x0*torch.ones(n_samples), std=1).to(dtype=torch.float64)\n",
    "#     Ts = torch.zeros((n_samples, n_steps, 2), dtype=torch.float64)\n",
    "#     Ks = torch.zeros((n_samples, n_steps, 2), dtype=torch.float64)\n",
    "\n",
    "#     # Generate sample paths\n",
    "#     for i in range(n_samples):\n",
    "        \n",
    "#         # Brownian increments\n",
    "#         dw = torch.normal(0., torch.sqrt(torch.tensor(dt)), size=(n_steps-1, ))\n",
    "\n",
    "#         # cut-off point t0\n",
    "#         i0 = idx[i]\n",
    "#         t0 = i0*dt\n",
    "\n",
    "#         # time samples\n",
    "#         ts[i] = t0\n",
    "\n",
    "#         # Theta^t\n",
    "#         Ts[i,:,0] = t_grid\n",
    "#         for j in range(i0, n_steps): \n",
    "#             t = j*dt\n",
    "#             integral = 0.\n",
    "#             for k in range(i0):\n",
    "#                 r = k*dt\n",
    "#                 integral += ((r-t)**a)*dw[k] \n",
    "#             Ts[i,j,1] = integral\n",
    "        \n",
    "#         # K^t\n",
    "#         for j in range(i0+1, n_steps):\n",
    "#             t = j*dt\n",
    "#             Ks[i, j, 1] = (t - t0)**a\n",
    "\n",
    "#     return idx, ts, xs, Ts, Ks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "X4bs3COkGJkm"
   },
   "outputs": [],
   "source": [
    "# def L(alphas, signature_kernel, t_cps, x_cps, T_cps, sigma_t, sigma_x, sigma_sig, batch_size, \n",
    "#       n_steps, T, x0, a, xi, eta, rho, phi, lambda_, penalty):\n",
    "    \n",
    "#     # nb of collocation points\n",
    "#     n_cps = alphas.shape[0]\n",
    "    \n",
    "#     # generate samples\n",
    "#     idx_batch, t_batch, x_batch, T_batch, K_batch = generator(batch_size, n_steps, T, x0, a, xi, eta, rho)\n",
    "    \n",
    "#     # compute first and second directional derivatives of sigkernel\n",
    "#     ksig, ksig_diff, ksig_diffdiff = signature_kernel.compute_kernel_and_derivatives_Gram(T_batch.to(device), \n",
    "#                                                                                           T_cps.to(device), \n",
    "#                                                                                           K_batch.to(device))\n",
    "            \n",
    "#     losses = torch.zeros((batch_size,))\n",
    "#     losses_T = torch.zeros((batch_size,))\n",
    "#     for j in range(batch_size): \n",
    "        \n",
    "#         # Sample t, x\n",
    "#         ind = idx_batch[j]\n",
    "#         t = t_batch[j]\n",
    "#         x = x_batch[j]\n",
    "#         wt = T_batch[j,ind,1]\n",
    "\n",
    "#         loss = 0.\n",
    "#         loss_T = 0.\n",
    "#         for i in range(n_cps):\n",
    "            \n",
    "#             # select collocation points\n",
    "#             ti = t_cps[i]\n",
    "#             xi = x_cps[i]\n",
    "                      \n",
    "#             # factors appearing in loss\n",
    "#             l_t = (t-ti)/(sigma_t**2) \n",
    "#             l_x = (x-xi)/(sigma_x**2) \n",
    "#             l_xx = (sigma_x**2 - (x-xi)**2)/(sigma_x**4)\n",
    "#             e_t = exp_kernel(t, ti, sigma_t)\n",
    "#             e_T = exp_kernel(T, ti, sigma_t)\n",
    "#             e_x = exp_kernel(x, xi, sigma_x)\n",
    "#             p = psi(t, wt, a, xi, eta)\n",
    "\n",
    "#             # terms in loss\n",
    "#             u_T  = e_T*e_x*ksig[j,i]\n",
    "#             D_t  = -l_t*e_t*e_x*ksig[j,i]\n",
    "#             D_x  = -l_x*e_t*e_x*ksig[j,i]\n",
    "#             D_xx = -l_xx*e_t*e_x*ksig[j,i]\n",
    "#             D_Kx = -l_x*e_t*e_x*ksig_diff[j,i]\n",
    "#             D_KK = e_t*e_x*ksig_diffdiff[j,i]\n",
    "\n",
    "#             # putting everything together\n",
    "#             loss += alphas[i]*(D_t -0.5*(p**2)*D_x + 0.5*(p**2)*D_xx + 0.5*D_KK + rho*p*D_Kx)\n",
    "#             loss_T += alphas[i]*u_T\n",
    "\n",
    "#         losses[j] = loss**2\n",
    "#         losses_T[j] = (loss_T - phi(x))**2\n",
    "\n",
    "#     return lambda_*torch.mean(losses) + (1.-lambda_)*torch.mean(losses_T) + penalty*torch.sum(alphas**2)\n",
    "\n",
    "\n",
    "# def evaluate(alphas, signature_kernel, t_cps, x_cps, T_cps, sigma_t, sigma_x, sigma_sig, t_batch, x_batch, T_batch):\n",
    "#     n_cps = alphas.shape[0]\n",
    "#     batch_size = t_batch.shape[0]\n",
    "#     out = torch.zeros((batch_size,))\n",
    "#     for j in range(batch_size):\n",
    "#         for i in range(n_cps):\n",
    "#             e_t = exp_kernel(t_batch[j], t_cps[i], sigma_t)\n",
    "#             e_x = exp_kernel(x_batch[j], x_cps[i], sigma_x)\n",
    "#             ksig = signature_kernel.compute_kernel(T_batch[j].unsqueeze(0).to(device), T_cps[i].unsqueeze(0).to(device))[0]\n",
    "#             out[j] = out[j] + alphas[i]*e_t*e_x*ksig\n",
    "#     return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # collocation points\n",
    "# _, t_cps, x_cps, T_cps, _ = generator(m+n, n_increments+1, T, mid_price, a, xi, eta, rho)\n",
    "\n",
    "# # Specify the static kernel \n",
    "# static_kernel = sigkernel.RBFKernel(sigma=sigma_sig)\n",
    "\n",
    "# # Initialize the corresponding signature kernel\n",
    "# signature_kernel = sigkernel.SigKernel(static_kernel, dyadic_order=1)\n",
    "\n",
    "# # randomly initialize the trainable parameters\n",
    "# alphas = torch.tensor(np.random.normal(size=m+n, scale=np.sqrt(1./m+n)), requires_grad=True)\n",
    "# # alphas = torch.zeros((n_cps,), requires_grad=True)\n",
    "\n",
    "# # for evaluation\n",
    "# t_batch_eval = torch.tensor(n_eval*[0.], dtype=torch.float64)\n",
    "# x_batch_eval = torch.tensor(xs_eval, dtype=torch.float64)\n",
    "# T_batch_eval = torch.zeros((n_eval, n_increments+1, 2), dtype=torch.float64)\n",
    "# T_batch_eval[:,:,0] = torch.linspace(0, 1, n_increments+1).to(dtype=torch.float64)\n",
    "\n",
    "# # optimiser\n",
    "# optimizer = torch.optim.Adam([alphas], lr=lr)\n",
    "\n",
    "# # scheduler\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=dt_scheduler, gamma=x_scheduler)\n",
    "\n",
    "# # store losses\n",
    "# losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iP48L5HtPwj5",
    "outputId": "ce4bd33a-19a6-4e59-b1df-4d187550bb4c"
   },
   "outputs": [],
   "source": [
    "# # training by gradient descent\n",
    "# for i in range(n_iter):\n",
    "    \n",
    "#     optimizer.zero_grad()\n",
    "    \n",
    "#     # computing loss\n",
    "#     loss = L(alphas, signature_kernel, t_cps, x_cps, T_cps, sigma_t, sigma_x, sigma_sig, \n",
    "#              batch_size, n_increments+1, T, mid_price, a, xi, eta, rho, phi, lambda_, penalty) \n",
    "    \n",
    "#     # storing the calculated loss\n",
    "#     losses.append(loss.item())\n",
    "    \n",
    "#     # backward pass for computing the gradients of the loss w.r.t to learnable parameters\n",
    "#     loss.backward()\n",
    "    \n",
    "#     # run optimiser\n",
    "#     optimizer.step()\n",
    "    \n",
    "#     # run scheduler to decrease learning rate\n",
    "#     scheduler.step()\n",
    "        \n",
    "#     # evaluation\n",
    "#     if i % print_every == 0:\n",
    "#         with torch.no_grad():\n",
    "#             sigkernel_prices_old = evaluate(alphas, signature_kernel, t_cps, x_cps, T_cps, sigma_t, sigma_x, sigma_sig, t_batch_eval, x_batch_eval, T_batch_eval)\n",
    "\n",
    "#             # priting the values for understanding\n",
    "#             print('iter: {}, call price: {:.2f}, loss: {:.3f}, learning rate: {:.6f} '.format(i, sigkernel_prices_old.mean().item(), loss.item(), scheduler.get_last_lr()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "XjwJTMcUI54N",
    "outputId": "0abfe2fe-187a-4ae5-92fb-d9efa643fa0d"
   },
   "outputs": [],
   "source": [
    "# plt.plot(losses)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
